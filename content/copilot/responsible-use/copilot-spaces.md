---
title: Responsible use of GitHub Copilot Spaces
shortTitle: Copilot Spaces
intro: 'Learn how to use GitHub Copilot Spaces responsibly by understanding its purposes, capabilities, and limitations.'
versions:
  feature: copilot
topics:
  - Copilot
contentType: rai
category: 
  - Responsible use
---

## About GitHub Copilot Spaces

Copilot Spaces let you organize the context that Copilot Chat uses to answer your questions. Spaces can include repositories, code, pull requests, issues, free-text content like transcripts or notes, images, and file uploads. You can ask Copilot questions grounded in that context, or share the space with your team to support collaboration and knowledge sharing. Spaces can also be accessed directly from the IDE via the remote GitHub MCP server.

### Input processing

When you submit a question in a space, Copilot Chat augments your request with relevant context from that space. Included context can be:

* Files and repositories you’ve added  
* Issues, pull requests, and documentation  
* Notes or transcripts you supply

The input prompt from the user is pre-processed by the Copilot Chat system, combined with additional contextual information (for example, the current date and time), and sent to a large language model. User input can take the form of code snippets or plain language.

The large language model will take the prompt, gather additional context (for example repository data stored on GitHub or search results from Bing), and provide a response based on the prompt.  English is the preferred language for submitted prompts.

### Language model analysis

The pre-processed prompt is then passed through the Copilot Chat language model, which is a neural network that has been trained on a large body of text data. The language model analyzes the input prompt.

### Response generation

The language model generates a response based on its analysis of the input prompt and the context provided to it. The language model can gather additional context (for example repository data stored on GitHub or search results from Bing), and provide a response based on the prompt.

### Output formatting

The response generated by Copilot Chat is formatted and presented to the user. Copilot may use syntax highlighting, indentation, and other formatting features to add clarity to the generated response. Depending upon the type of question from the user, links to context that the model used when generating a response, such as source code files, issues, Bing search results, or documentation, may also be provided.

Copilot Chat is intended to provide you with the most relevant answer to your question. However, it may not always provide the answer you are looking for. Users of Copilot Chat are responsible for reviewing and validating responses generated by the system to ensure they are accurate and appropriate. Additionally, as part of our product development process, we undertake red teaming to understand and improve the safety of Copilot Chat. Input prompts and output completions are run through content filters. The content filtering system detects and prevents the output on specific categories of content including harmful, offensive, or off-topic content. For more information on improving the performance of Copilot Chat, see [Improving performance for Copilot Chat](/copilot/responsible-use/chat-in-github#improving-performance-for-copilot-chat).

## Use cases for Spaces

### Developing a new feature

Spaces let you bundle relevant code, product specs, and design notes so Copilot can quickly explain the current implementation, highlight gaps, and draft new code or next steps. This helps you save time, stay aligned with requirements, and produce higher-quality feature work.

### Defining the logic for a small, frequent task

For repetitive tasks like adding telemetry or event handling, Spaces make it easy to document the process once and reuse it. By grounding Copilot in flowcharts, examples, or schemas, you ensure consistent patterns, reusable templates, and efficient execution across your team.

### Sharing knowledge with teammates

Spaces can act as living guides for common project questions (e.g. how authentication or search works) by collecting the latest code and documentation in one place. Copilot then uses that context to explain systems, answer questions, and onboard teammates quickly with best practices.

## Improving performance for Spaces

Spaces can be used in a wide variety of development and collaboration workflows, from generating code to sharing knowledge across a team. To improve performance and get more relevant responses, there are several best practices you can adopt. For details on system constraints, see [Limitations of GitHub Copilot Spaces](#limitations-of-github-copilot-spaces).

### Be selective with context

Adding only the most relevant files, repositories, and notes helps Copilot stay focused. Overloading a space with unnecessary content can dilute the quality of responses and make it harder to get precise results.

### Keep context updated

As your project evolves, refresh the files, issues, or documentation in your space. Out-of-date context may cause Copilot to generate inaccurate or incomplete answers.

### Use instructions alongside sources

Combining natural language instructions with curated sources helps Copilot better understand your intent. Instructions provide guidance, while sources ground the output in real project context.

### Anchor chat in a space

 Starting your conversations from within a space ensures continuity and relevance. This keeps Copilot’s responses aligned with the specific context you’ve already set up, instead of resetting with each new chat.

### Verify Space’s output

Spaces ground Copilot’s responses in the context you provide, but the system may still make mistakes. These mistakes could be misunderstandings of your intent or simple errors in the generated response. Always review Copilot’s output carefully to confirm it behaves as intended, and ensure it meets your team’s quality and security standards before using it in production.

## Limitations of GitHub Copilot Spaces

### Interpretation of user intent

Spaces help ground Copilot Chat’s responses in curated context, but the system may still misunderstand your intent. Always review Copilot’s output to confirm it reflects your goals before using it in your project.

### Context limits

Spaces have defined size limits, and Copilot Chat only processes a portion of the content you include. This means not every file, document, or note in a Space will be used in a response. Being selective about what you add helps ensure that Copilot works with the most relevant context.

### Limited scope

Spaces that contain only a repository cannot currently be accessed in the IDE via the GitHub MCP server. To use Spaces in the IDE, you’ll need to include additional context such as files, issues, or documentation.

Spaces is backed by Copilot Chat, and therefore has been trained on a large body of code but still has a limited scope and may not be able to handle more complex code structures or obscure programming languages. For each language, the quality of suggestions you receive may depend on the volume and diversity of training data for that language. For example, JavaScript is well-represented in public repositories and is one of GitHub Copilot's best supported languages. Languages with less representation in public repositories may be more challenging for Copilot Chat to provide assistance with. Additionally, Copilot Chat can only suggest code based on the context of the code being written, so it may not be able to identify larger design or architectural issues.

### Inaccurate responses

Even when grounded in a Space, Copilot Chat may generate responses that are inaccurate, incomplete, or outdated. This applies to all types of outputs, including code, summaries, or issue drafts. Always validate results against your own project requirements.

### Security limitations

Copilot Chat generates code based on the context of the code being written, which can potentially expose sensitive information or vulnerabilities if not used carefully. You should be careful when using Copilot Chat to generate code for security-sensitive applications and always review and test the generated code thoroughly.

### Legal and regulatory considerations

Users need to evaluate potential specific legal and regulatory obligations when using any AI services and solutions, which may not be appropriate for use in every industry or scenario. Additionally, AI services or solutions are not designed for and may not be used in ways prohibited in applicable terms of service and relevant codes of conduct.

### Offensive content

Spaces utilizes Copilot Chat which has built-in protections against harmful, hateful, or offensive content. Please report any examples of offensive content to copilot-safety@github.com.
