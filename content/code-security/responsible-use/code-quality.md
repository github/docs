---
title: Responsible use of GitHub Code Quality
shortTitle: Code quality
intro: Use {% data variables.product.prodname_code_quality %} responsibly by understanding its purposes, capabilities, and limitations.
versions:
  feature: code-quality
topics:
  - Code Quality
  - CodeQL
  - AI
contentType: rai
redirect_from:
  - /code-security/code-quality/responsible-use/code-quality
---

{% data reusables.code-quality.code-quality-preview-note %}

## About {% data variables.product.prodname_code_quality %}

{% data variables.product.prodname_code_quality %} helps users improve code reliability, maintainability, and overall project health by surfacing actionable feedback and offering automatic fixes for any findings in pull requests and on the default branch.

When you enable {% data variables.product.prodname_code_quality_short %}, two types of analysis run:

* **{% data variables.product.prodname_codeql %} quality queries** run using {% data variables.product.prodname_code_scanning %} analysis and identify problems with the maintainability, reliability, or style of code. This runs on changed code in all pull requests against the default branch. It also runs periodically on the full default branch.

* **Large Language Model (LLM)-powered analysis** provides additional insights into potential quality concerns beyond what is covered by deterministic engines like {% data variables.product.prodname_codeql %}. This runs automatically on files changed in recent pushes to the default branch. These findings are displayed in {% data variables.product.prodname_code_quality_short %}'s **{% data variables.code-quality.recent_suggestions %}** dashboard, under the Security tab of the repository.

When a quality issue is detected by either type of analysis, **{% data variables.copilot.copilot_autofix_short %}** suggests a relevant fix that can be reviewed and applied by developers.

On pull requests, {% data variables.product.prodname_code_quality_short %} results are displayed as comments left by the `github-code-quality` bot, which includes a suggested autofix wherever possible.

## LLM-powered analysis for recent pushes

After each push to the default branch, the LLM analyzes recently changed files for maintainability, reliability, and other quality issues. {% data variables.product.prodname_code_quality_short %} inspects your code and provides feedback using a combination of natural language processing and machine learning.

### Input processing

The code changes are combined with other relevant, contextual information to form a prompt, and that prompt is sent to a large language model.

### Language model analysis

The prompt is then passed through the {% data variables.product.prodname_copilot_short %} language model, which is a neural network that has been trained on a large body of text data. The language model analyzes the input prompt.

### Response generation

The language model generates a response based on its analysis of the input prompt. This response can take the form of natural language suggestions and code suggestions.

### Output formatting

The response generated by {% data variables.product.prodname_code_quality_short %} is presented to the user directly, providing code feedback linked to specific lines of specific files. Where {% data variables.product.prodname_code_quality_short %} has provided a code suggestion, the suggestion is presented as a suggested change, which can be applied with a couple of clicks.

## {% data variables.copilot.copilot_autofix %} suggestions

On pull requests, {% data variables.product.prodname_code_quality_short %} results found by {% data variables.product.prodname_code_scanning %} analysis send input to the LLM. If the LLM can generate a potential fix, the `github-code-quality` bot posts a comment with a suggested change directly in the pull request.

In addition, users can request autofix generation for results in the default branch.

For more information on the suggestion generation process for {% data variables.copilot.copilot_autofix %}, see [AUTOTITLE](/code-security/code-scanning/managing-code-scanning-alerts/responsible-use-autofix-code-scanning).

## Use case for {% data variables.product.prodname_code_quality %}

The goal of {% data variables.product.prodname_code_quality %} is to:

* Surface code quality issues across your repository, so developers and repository administrators can quickly identify, prioritize and report on areas of risk.
* Accelerate remediation work by offering {% data variables.copilot.copilot_autofix_short %} suggestions for results found by scans of the default branch, as well as for findings in recent pushes to the default branch.
* Quickly provide actionable feedback on a developer's code. On pull requests, {% data variables.product.prodname_code_quality_short %} combines information on best practices with details of the codebase and findings to suggest a potential fix to the developer.

## Improving the performance of {% data variables.product.prodname_code_quality %}

If you encounter any issues or limitations with suggested fixes on pull requests, we recommend that you provide feedback by using the thumbs up and thumbs down buttons on the `github-code-quality` bot's comments. This can help {% data variables.product.github %} to improve the tool and address any concerns or limitations.

## Limitations of {% data variables.product.prodname_code_quality %}

### Limitations of {% data variables.product.prodname_code_quality_short %}'s LLM-powered analysis

{% data variables.product.prodname_code_quality_short %}'s LLM-powered analysis uses the same underlying language model and analysis engine as {% data variables.copilot.copilot_code-review %}. Therefore, it shares similar limitations when analyzing code quality. Key considerations include:

* Incomplete detection
* False positives
* Code suggestion accuracy
* Potential biases

For detailed information about these limitations, see [AUTOTITLE](/copilot/responsible-use/code-review).

You should always review the findings surfaced by {% data variables.product.prodname_code_quality %}'s LLM-powered analysis to verify their accuracy and applicability to your codebase.

### Limitations of {% data variables.copilot.copilot_autofix_short %}

{% data variables.copilot.copilot_autofix_short %} for {% data variables.product.prodname_code_quality_short %} findings won't be able to generate a fix for every finding in every situation. The feature operates on a best-effort basis and is not guaranteed to succeed 100% of the time.

When you review a suggestion from {% data variables.copilot.copilot_autofix_short %}, you must always consider the limitations of AI and edit the changes as needed before you accept the changes. You should always carefully review and verify {% data variables.copilot.copilot_autofix_short %} suggestions before applying them.

For more information on the limitations of {% data variables.copilot.copilot_autofix_short %}, the quality of {% data variables.copilot.copilot_autofix_short %} suggestions, and the best way to mitigate its limitations, see [AUTOTITLE](/code-security/code-scanning/managing-code-scanning-alerts/responsible-use-autofix-code-scanning)

## Provide feedback

You can provide feedback on {% data variables.product.prodname_code_quality %} in the [community discussion](https://github.com/orgs/community/discussions/177488).

## Next steps

See how {% data variables.product.prodname_code_quality %} works on your default branch to surface code quality issues and help you understand your repository's code health at a glance. See [AUTOTITLE](/code-security/code-quality/get-started/quickstart).
